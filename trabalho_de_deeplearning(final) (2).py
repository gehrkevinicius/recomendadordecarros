# -*- coding: utf-8 -*-
"""Trabalho de DeepLearning(FINAL).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LEStGyLt2TPmmV6YMOsrDrsBRhTFjvDJ
"""

!pip install -q langchain openai python-dotenv pandas
!pip install langchain-community
!pip install langchain-experimental
!pip install -q gradio
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import gradio as gr
import os
import getpass
import re
from langchain.chat_models import ChatOpenAI
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain.agents.agent_types import AgentType
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

df = pd.read_csv('data.csv')
print(df.head())
df.info()

colunas_limpas = ['Make', 'Model', 'Year', 'Engine HP', 'Engine Cylinders',
                 'Transmission Type', 'Driven_Wheels', 'Number of Doors',
                 'Market Category', 'Vehicle Size', 'highway MPG', 'city mpg',
                 'Popularity', 'MSRP']

df = df[colunas_limpas].dropna().drop_duplicates().reset_index(drop=True)

print({len(df)})

os.environ["OPENAI_API_KEY"] = "sk-qTcYyqGkbx3qBNp2w6RrPEqkklmxWWDK7QD-lIfcX5T3BlbkFJyffZzMox5wwx5W1ENuyR7tPzQxreLbcZ09gzvZH-MA"

llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0.1,
    openai_api_key=os.environ["OPENAI_API_KEY"]
)

agente = create_pandas_dataframe_agent(llm, df, verbose=True, allow_dangerous_code=True, agent_type=AgentType.OPENAI_FUNCTIONS)

scaler = MinMaxScaler()


df['Engine HP Normalized'] = scaler.fit_transform(df[['Engine HP']])
df['city mpg Normalized'] = scaler.fit_transform(df[['city mpg']])
df['Popularity Normalized'] = scaler.fit_transform(df[['Popularity']])

df = df.copy()
peso_ano = 0.25
peso_preco = 0.30
peso_potencia = 0.20
peso_consumo = 0.15
peso_popularidade = 0.15

df['score'] = (
    df['Engine HP Normalized'] * peso_potencia +
    df['city mpg Normalized'] * peso_consumo +
    df['Popularity Normalized'] * peso_popularidade
)

X = df.drop(columns=['Make', 'Model', 'score'])
y = df['score']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

treino_df = keras.Sequential([
    layers.Dense(256, activation='relu', input_shape=[X_train.shape[1]]),
    layers.Dense(128, activation='relu'),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

def interpretar_pergunta(texto):
    import re
    texto_lower = texto.lower()
    preferencias = {}

    # --- Preço máximo ---
    match_preco = re.search(r'([\d\.]+)', texto_lower)
    if match_preco:
        try:
            preco_num = float(match_preco.group(1).replace('.', '').replace(',', ''))
            if 'mil' in texto_lower or 'k' in texto_lower:
                preco_num *= 1000
            preferencias['msrp_max'] = int(preco_num)
        except ValueError:
            pass

    marcas_possiveis = df['Make'].str.lower().unique()
    for marca in marcas_possiveis:
        if marca in texto_lower:
            preferencias['make'] = marca.title()
            break

    estilos_usuario = {
    "suv": "Crossover",
    "crossover": "Crossover",
    "hatch": "Hatchback",
    "hatchback": "Hatchback",
    "sedan": "Sedan",
    "esportivo": "High-Performance",
    "luxo": "Luxury",
    "elétrico": "Hybrid",
}

    for termo, categoria in estilos_usuario.items():
      if termo in texto_lower:
        preferencias['market_category'] = categoria
        break

    for chave, valor in estilos_usuario.items():
        if chave in texto_lower:
            preferencias['vehicle_size'] = valor
            break

    return preferencias

# --- Cérebro Recomendador (Lógica de Ranking) ---
def fazer_recomendacao(preferencias):
    df_filtrado = df.copy()

    if 'msrp_max' in preferencias:
        df_filtrado = df_filtrado[df_filtrado['MSRP'] <= preferencias['msrp_max']]

    if 'make' in preferencias:
        df_filtrado = df_filtrado[df_filtrado['Make'].str.lower() == preferencias['make'].lower()]

    if 'market_category' in preferencias:
        df_filtrado = df_filtrado[df_filtrado['Market Category'].str.contains(preferencias['market_category'], case=False, na=False)]

    if not df_filtrado.empty:
        resultados = (
            df_filtrado
            .sort_values(by='score', ascending=False)
            .drop_duplicates(subset=['Make', 'Model'])
            .head(3)


        )

        resposta = "Com base nos seus critérios, encontrei estas ótimas opções com o melhor 'score' de qualidade:\n\n"
        for i, (_, carro) in enumerate(resultados.iterrows()):
            resposta += (f"{i+1}. {carro['Make']} {carro['Model']} ({int(carro['Year'])})\n"
                         f"   - Preço (MSRP): ${carro['MSRP']:,.2f}\n"
                         f"   - Potência: {int(carro['Engine HP'])} HP\n"
                         f"   - Consumo (Cidade): {int(carro['city mpg'])} MPG\n\n")
        return resposta

    else:
        return "Desculpe, não encontrei nenhum carro que atenda a todos os seus critérios. Tente ser um pouco menos específico."

# --- Função Principal (Roteador) ---

def responder_extremos_preco(pergunta):
    if 'mais caro' in pergunta:
        carro = df.sort_values(by='MSRP', ascending=False).iloc[0]
        tipo = "mais caro"
    else:
        carro = df.sort_values(by='MSRP', ascending=True).iloc[0]
        tipo = "mais barato"

    resposta = (
        f"O carro {tipo} do dataset é:\n\n"
        f"{carro['Make']} {carro['Model']} ({int(carro['Year'])})\n"
        f"- Preço (MSRP): ${carro['MSRP']:,.2f}\n"
        f"- Potência: {int(carro['Engine HP'])} HP\n"
        f"- Consumo (Cidade): {int(carro['city mpg'])} MPG\n"
    )
    return resposta

def agente_de_carros(pergunta):
    """
    Esta é a função principal que decide o que fazer com a pergunta do usuário.
    """
    pergunta_lower = pergunta.lower()

    if 'mais caro' in pergunta_lower or 'mais barato' in pergunta_lower:
        return responder_extremos_preco(pergunta_lower)
    else:
        preferencias = interpretar_pergunta(pergunta)
        return fazer_recomendacao(preferencias)

ifr = gr.Interface(
    fn = agente_de_carros,
    inputs = gr.Textbox(lines=2, placeholder="Digite sua pergunta..."),
    outputs = "text",
    title="Agente de escolha de carros",
    description="Faça perguntas para achar seu carro ideal"
)

ifr.launch(debug=True)